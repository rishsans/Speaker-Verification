<h1 align="center" id="title">ECAPA-based Speaker Verification of Virtual Assistants: A Transfer Learning Approach</h1>

<p align="center"><img src="https://socialify.git.ci/rishsans/Speaker-Verification/image?description=1&amp;descriptionEditable=Assessing%20%20the%20efficiency%20of%20transfer%20learning%20%20to%20examine%20the%20accuracy%20%26%20reliability%20of%20Speaker%0Averification%20for%20Speech%20assistants&amp;name=1&amp;owner=1&amp;pattern=Solid&amp;theme=Dark" alt="project-image"></p>

<h2> Overview</h2>
<p id="description">
The widespread use of speech assistants like Siri, Cortana, Google Assistant, and Alexa has presented new challenges for speaker verification. While speaker recognition technology has been in use for years to identify individuals based on their distinctive voice characteristics, these virtual speech assistants are typically produced using Text-to-Speech (TTS) technology, and therefore lack the natural variations present in human voices. This project explores the use of transfer learning to adapt existing speaker recognition models to recognize synthetic voices produced by TTS technology.
</p>

<h2>Methodology</h2>
<p id="description">
The project uses a pre-trained ECAPA-TDNN model from the SpeechBrain toolkit and adapts it using transfer learning to recognize synthetic voices produced by TTS technology. The model has originally been trained on human voices using the VoxCeleb2 dataset. The study assesses the accuracy and reliability of speaker verification for both text-dependent and text-independent voice samples.

Text-dependent voice samples refer to situations where the speaker is prompted to say a specific phrase or set of phrases, while text-independent voice samples refer to situations where the speaker can say any phrase or sentence. In this project, both types of samples are used to test the accuracy of the model.
</p>


<h2>Results</h2>
<p id="description">
The results indicate that transfer learning on the ECAPA-TDNN model is effective in achieving 100% accuracy for text-independent voice samples, while text-dependent voice samples achieve 80% accuracy for the 4 virtual speech assistants. This suggests that transfer learning can be a useful technique for adapting existing speaker recognition models to recognize synthetic voices produced by TTS technology.
</p>
<h2>Project Screenshots</h2>
<a href="https://ibb.co/2yQzf4W"><img src="https://i.ibb.co/c1HW7nk/71.jpg" alt="71" border="0" width="300"></a><br /><a target='_blank' href='https://imgbb.com/'></a>

